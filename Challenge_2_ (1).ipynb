{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCp91fDE7MQ1"
      },
      "source": [
        "# Aurora Bay FAQ Chatbot with Vector Search & Gemini\n",
        "\n",
        "This notebook demonstrates how to build an intelligent FAQ chatbot using:\n",
        "- **BigQuery** to store and query FAQ data\n",
        "- **Vertex AI Embeddings** to generate semantic vector representations\n",
        "- **BigQuery Vector Search** to find the most relevant FAQ entries\n",
        "- **Gemini** to generate natural language answers\n",
        "\n",
        "### Architecture Overview\n",
        "```\n",
        "User Question\n",
        "     ↓\n",
        "Generate Embedding (text-embedding-005)\n",
        "     ↓\n",
        "Vector Search in BigQuery\n",
        "     ↓\n",
        "Top-K Relevant FAQs\n",
        "     ↓\n",
        "Gemini (gemini-2.0-flash) → Natural Language Answer\n",
        "```\n",
        "\n",
        "### Prerequisites\n",
        "- A Google Cloud Project with billing enabled\n",
        "- The following APIs enabled:\n",
        "  - BigQuery API\n",
        "  - Vertex AI API\n",
        "- Sufficient IAM permissions (BigQuery Admin, Vertex AI User)"
      ],
      "id": "kCp91fDE7MQ1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dg9p1St7MQ2"
      },
      "source": [
        "## Step 1: Install & Import Dependencies\n",
        "\n",
        "Install required Python packages. These are typically pre-installed in Colab Enterprise,\n",
        "but we ensure the correct versions are available."
      ],
      "id": "-dg9p1St7MQ2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Nl3pcD-7MQ2"
      },
      "outputs": [],
      "source": [
        "# Install/upgrade necessary packages\n",
        "!pip install --upgrade google-cloud-bigquery \\\n",
        "                        google-cloud-aiplatform \\\n",
        "                        db-dtypes \\\n",
        "                        pandas \\\n",
        "                        tqdm -q"
      ],
      "id": "6Nl3pcD-7MQ2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36-8nhaD7MQ3",
        "outputId": "d7bf6341-6e27-405d-92c0-ffc2fff4b6ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All packages imported successfully.\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# Core imports\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "import time\n",
        "import json\n",
        "import textwrap\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm                    # Progress bars\n",
        "\n",
        "# Google Cloud – BigQuery\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.bigquery import LoadJobConfig, SourceFormat\n",
        "\n",
        "# Vertex AI – Embeddings & Gemini\n",
        "import vertexai\n",
        "from vertexai.language_models import TextEmbeddingModel\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "\n",
        "print(\"✅ All packages imported successfully.\")"
      ],
      "id": "36-8nhaD7MQ3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbSjIvY57MQ3"
      },
      "source": [
        "## Step 2: Configuration\n",
        "\n",
        "Set your Google Cloud **project ID** and preferred **region** below.\n",
        "All resources (BigQuery dataset, Vertex AI calls) will use these settings."
      ],
      "id": "FbSjIvY57MQ3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKVEAv7U7MQ3",
        "outputId": "ec60a823-3655-4e10-8ef8-45e77483df30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuration complete.\n",
            "   Project : qwiklabs-gcp-02-689e008843d4\n",
            "   Region  : us-central1\n",
            "   Dataset : aurora_bay\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# ⚙️  USER CONFIGURATION — update these values before running\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "PROJECT_ID   = \"qwiklabs-gcp-02-689e008843d4\"       # e.g. \"my-gcp-project-123\"\n",
        "REGION       = \"us-central1\"           # Vertex AI region\n",
        "BQ_DATASET   = \"aurora_bay\"            # BigQuery dataset name (will be created)\n",
        "BQ_TABLE     = \"faqs\"                  # Raw FAQ table\n",
        "BQ_EMB_TABLE = \"faqs_with_embeddings\" # Table that stores embeddings\n",
        "\n",
        "# Source data in Google Cloud Storage\n",
        "GCS_URI = \"gs://labs.roitraining.com/aurora-bay-faqs/aurora-bay-faqs.csv\"\n",
        "\n",
        "# Vertex AI model identifiers\n",
        "EMBEDDING_MODEL = \"text-embedding-005\"  # Latest text embedding model\n",
        "GEMINI_MODEL    = \"gemini-2.0-flash-001\" # Fast, capable Gemini model\n",
        "\n",
        "# Number of similar FAQs to retrieve for each user question\n",
        "TOP_K = 3\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "# Initialise Vertex AI SDK\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "# Initialise BigQuery client\n",
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "print(f\"✅ Configuration complete.\")\n",
        "print(f\"   Project : {PROJECT_ID}\")\n",
        "print(f\"   Region  : {REGION}\")\n",
        "print(f\"   Dataset : {BQ_DATASET}\")"
      ],
      "id": "DKVEAv7U7MQ3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NjCbLJ37MQ4"
      },
      "source": [
        "## Step 3: Create BigQuery Dataset & Import CSV\n",
        "\n",
        "We create a BigQuery dataset (if it doesn't already exist) and then load the\n",
        "Aurora Bay FAQ CSV directly from Google Cloud Storage."
      ],
      "id": "0NjCbLJ37MQ4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo6GoL8n7MQ4",
        "outputId": "20feaf3c-e0b9-4ba5-d342-723ebbf3c9c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset 'aurora_bay' is ready.\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 3a. Create the BigQuery dataset (skip if already exists)\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "dataset_ref = bigquery.Dataset(f\"{PROJECT_ID}.{BQ_DATASET}\")\n",
        "dataset_ref.location = \"US\"  # Multi-region for flexibility\n",
        "\n",
        "try:\n",
        "    bq_client.create_dataset(dataset_ref, exists_ok=True)\n",
        "    print(f\"✅ Dataset '{BQ_DATASET}' is ready.\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️  Could not create dataset: {e}\")"
      ],
      "id": "fo6GoL8n7MQ4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbkUiXlX7MQ4",
        "outputId": "0d842bd3-6368-4292-8250-3d5e30fc6461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Loading data from:\n",
            "   gs://labs.roitraining.com/aurora-bay-faqs/aurora-bay-faqs.csv\n",
            "   → qwiklabs-gcp-02-689e008843d4.aurora_bay.faqs\n",
            "\n",
            "✅ Load complete! Table has 51 rows.\n",
            "\n",
            "Schema:\n",
            "  question                       STRING\n",
            "  answer                         STRING\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 3b. Load the CSV from GCS into BigQuery\n",
        "#\n",
        "# The aurora-bay-faqs.csv has NO header row — the file starts\n",
        "# directly with data. If we used autodetect with skip_leading_rows=1\n",
        "# BigQuery would silently drop the first real data row and name\n",
        "# columns 'string_field_0', 'string_field_1', etc.\n",
        "#\n",
        "# Fix: supply an explicit schema AND set skip_leading_rows=0\n",
        "# so every row is treated as data with the names we define.\n",
        "# WRITE_TRUNCATE replaces the table on each run (idempotent).\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "table_ref = f\"{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}\"\n",
        "\n",
        "# Explicit schema: two STRING columns with meaningful names\n",
        "faq_schema = [\n",
        "    bigquery.SchemaField(\"question\", \"STRING\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\"answer\",   \"STRING\", mode=\"NULLABLE\"),\n",
        "]\n",
        "\n",
        "job_config = LoadJobConfig(\n",
        "    source_format     = SourceFormat.CSV,\n",
        "    skip_leading_rows = 0,              # No header row in this file\n",
        "    schema            = faq_schema,     # Explicit column names & types\n",
        "    write_disposition = \"WRITE_TRUNCATE\",\n",
        ")\n",
        "\n",
        "print(f\"⏳ Loading data from:\\n   {GCS_URI}\")\n",
        "print(f\"   → {table_ref}\\n\")\n",
        "\n",
        "load_job = bq_client.load_table_from_uri(\n",
        "    GCS_URI, table_ref, job_config=job_config\n",
        ")\n",
        "load_job.result()  # Wait for the job to complete\n",
        "\n",
        "# Retrieve and display table metadata\n",
        "table = bq_client.get_table(table_ref)\n",
        "print(f\"✅ Load complete! Table has {table.num_rows:,} rows.\")\n",
        "print(\"\\nSchema:\")\n",
        "for field in table.schema:\n",
        "    print(f\"  {field.name:30s} {field.field_type}\")"
      ],
      "id": "rbkUiXlX7MQ4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "eKks2-8H7MQ4",
        "outputId": "3e4aa0c4-741d-49c9-8d40-89cff5ca6018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preview of 'faqs' table:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     question  \\\n",
              "0                                    question   \n",
              "1                When was Aurora Bay founded?   \n",
              "2       What is the population of Aurora Bay?   \n",
              "3  Where is the Aurora Bay Town Hall located?   \n",
              "4     Who is the current mayor of Aurora Bay?   \n",
              "\n",
              "                                              answer  \n",
              "0                                             answer  \n",
              "1  Aurora Bay was founded in 1901 by a group of f...  \n",
              "2  Aurora Bay has a population of approximately 3...  \n",
              "3  The Town Hall is located at 100 Harbor View Ro...  \n",
              "4  The current mayor is Linda Greenwood, elected ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c6f48a4-f490-4391-9254-df32b43b9de6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>question</td>\n",
              "      <td>answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When was Aurora Bay founded?</td>\n",
              "      <td>Aurora Bay was founded in 1901 by a group of f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the population of Aurora Bay?</td>\n",
              "      <td>Aurora Bay has a population of approximately 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Where is the Aurora Bay Town Hall located?</td>\n",
              "      <td>The Town Hall is located at 100 Harbor View Ro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who is the current mayor of Aurora Bay?</td>\n",
              "      <td>The current mayor is Linda Greenwood, elected ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c6f48a4-f490-4391-9254-df32b43b9de6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c6f48a4-f490-4391-9254-df32b43b9de6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c6f48a4-f490-4391-9254-df32b43b9de6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_8be5b5d3-a780-4727-9ed2-194b9f94f18a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_preview')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8be5b5d3-a780-4727-9ed2-194b9f94f18a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_preview');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_preview",
              "summary": "{\n  \"name\": \"df_preview\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"When was Aurora Bay founded?\",\n          \"Who is the current mayor of Aurora Bay?\",\n          \"What is the population of Aurora Bay?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Aurora Bay was founded in 1901 by a group of fur traders who recognized the region\\u2019s strategic coastal location.\",\n          \"The current mayor is Linda Greenwood, elected in 2021 for a four-year term.\",\n          \"Aurora Bay has a population of approximately 3,200 residents, although it can fluctuate seasonally due to temporary fishing and tourism workforces.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 3c. Preview the imported data\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "preview_query = f\"\"\"\n",
        "    SELECT *\n",
        "    FROM `{table_ref}`\n",
        "    LIMIT 5\n",
        "\"\"\"\n",
        "\n",
        "df_preview = bq_client.query(preview_query).to_dataframe()\n",
        "print(f\"Preview of '{BQ_TABLE}' table:\")\n",
        "df_preview"
      ],
      "id": "eKks2-8H7MQ4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqTBFfoe7MQ4"
      },
      "source": [
        "## Step 4: Generate Embeddings\n",
        "\n",
        "We use Vertex AI's `text-embedding-005` model to create a semantic vector\n",
        "for each FAQ entry. The embedding is computed over the **combined question\n",
        "and answer text**, so that similarity search works on meaning, not just keywords.\n",
        "\n",
        "> **Why combine question + answer?**  \n",
        "> A user's query may match either the question wording *or* key terms in the\n",
        "> answer. Embedding both together gives the richest representation."
      ],
      "id": "SqTBFfoe7MQ4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJZAppu47MQ4",
        "outputId": "63c19f3b-fec0-4cb8-cbf7-b7b416dde46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 51 FAQ rows.\n",
            "Columns: ['question', 'answer']\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 4a. Load all FAQs from BigQuery into a Pandas DataFrame\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "all_faqs_query = f\"SELECT * FROM `{table_ref}`\"\n",
        "df_faqs = bq_client.query(all_faqs_query).to_dataframe()\n",
        "\n",
        "print(f\"Loaded {len(df_faqs):,} FAQ rows.\")\n",
        "print(f\"Columns: {list(df_faqs.columns)}\")"
      ],
      "id": "oJZAppu47MQ4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pywcVmZJ7MQ4",
        "outputId": "6382a814-1236-4b5e-953b-5125c743263f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question column : 'question'\n",
            "Answer column   : 'answer'\n",
            "\n",
            "Sample values:\n",
            "                             question                                                                                                                                              answer\n",
            "                             question                                                                                                                                              answer\n",
            "         When was Aurora Bay founded?                                    Aurora Bay was founded in 1901 by a group of fur traders who recognized the region’s strategic coastal location.\n",
            "What is the population of Aurora Bay? Aurora Bay has a population of approximately 3,200 residents, although it can fluctuate seasonally due to temporary fishing and tourism workforces.\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 4b. Set question and answer column names\n",
        "#\n",
        "# Because the CSV has no header row we supplied an explicit schema\n",
        "# in Step 3b, so the column names are always 'question' and 'answer'.\n",
        "# We confirm they exist and print a quick sanity check.\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "\n",
        "QUESTION_COL = \"question\"\n",
        "ANSWER_COL   = \"answer\"\n",
        "\n",
        "# Verify the columns are present before proceeding\n",
        "missing = [c for c in [QUESTION_COL, ANSWER_COL] if c not in df_faqs.columns]\n",
        "if missing:\n",
        "    raise ValueError(\n",
        "        f\"Expected columns not found: {missing}\\n\"\n",
        "        f\"Actual columns: {list(df_faqs.columns)}\\n\"\n",
        "        \"Re-run Step 3b to reload the table with the correct schema.\"\n",
        "    )\n",
        "\n",
        "print(f\"Question column : '{QUESTION_COL}'\")\n",
        "print(f\"Answer column   : '{ANSWER_COL}'\")\n",
        "print(f\"\\nSample values:\")\n",
        "print(df_faqs[[QUESTION_COL, ANSWER_COL]].head(3).to_string(index=False))"
      ],
      "id": "pywcVmZJ7MQ4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1f6XuQ27MQ4",
        "outputId": "e93e1316-af7c-4f39-acc9-2b49521650f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Embedding model 'text-embedding-005' loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 4c. Helper function: generate embeddings via Vertex AI\n",
        "#\n",
        "# The API accepts up to 250 texts per batch. We process rows in\n",
        "# batches of 100 to stay well within limits and avoid timeouts.\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "\n",
        "embedding_model = TextEmbeddingModel.from_pretrained(EMBEDDING_MODEL)\n",
        "\n",
        "BATCH_SIZE = 100  # Texts per API call\n",
        "\n",
        "def generate_embeddings_batch(texts: list[str]) -> list[list[float]]:\n",
        "    \"\"\"\n",
        "    Generate text embeddings for a list of strings.\n",
        "\n",
        "    Args:\n",
        "        texts: List of text strings to embed.\n",
        "\n",
        "    Returns:\n",
        "        List of embedding vectors (one per input text).\n",
        "    \"\"\"\n",
        "    all_embeddings = []\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), BATCH_SIZE), desc=\"Embedding batches\"):\n",
        "        batch = texts[i : i + BATCH_SIZE]\n",
        "        try:\n",
        "            results = embedding_model.get_embeddings(batch)\n",
        "            all_embeddings.extend([r.values for r in results])\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️  Error on batch {i//BATCH_SIZE}: {e}\")\n",
        "            # Fill with None so row indices remain aligned\n",
        "            all_embeddings.extend([None] * len(batch))\n",
        "\n",
        "        # Polite delay to avoid quota exhaustion on large datasets\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    return all_embeddings\n",
        "\n",
        "print(f\"✅ Embedding model '{EMBEDDING_MODEL}' loaded.\")"
      ],
      "id": "n1f6XuQ27MQ4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "c2fa8e44a485433b8a8f78a6ef886140",
            "de77f560c1b64310a371b206c9a6ccf2",
            "f5767e114aa844ecbc51fc1e888599b6",
            "c95c0785aa0b419ca8a02a7aeac5461f",
            "49b2146a6c09488e81c196f27070b976",
            "13953e8713e54dcc88997f8cf0e1ec03",
            "ed8139d7f6a54d21946b9cfec2ff070d",
            "53066e9e118e45f28d168ef91c5ee423",
            "5b92796d8d6140bca3ca0255fc5bc872",
            "b0f48079d7c24f648e4784133dc1a520",
            "a52678b552344c42a824a7ed31c37953"
          ]
        },
        "id": "uO55OB377MQ5",
        "outputId": "7ed038e4-b5e3-4877-835a-f7035b08138b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings for 51 FAQ entries...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Embedding batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2fa8e44a485433b8a8f78a6ef886140"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Embeddings generated! Dimension: 768\n",
            "   Rows with valid embeddings: 51\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 4d. Create combined text and generate embeddings\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "\n",
        "# Build combined Q+A strings for embedding\n",
        "df_faqs[\"combined_text\"] = (\n",
        "    \"Question: \" + df_faqs[QUESTION_COL].fillna(\"\") +\n",
        "    \" Answer: \"  + df_faqs[ANSWER_COL].fillna(\"\")\n",
        ")\n",
        "\n",
        "print(f\"Generating embeddings for {len(df_faqs)} FAQ entries...\")\n",
        "combined_texts = df_faqs[\"combined_text\"].tolist()\n",
        "\n",
        "embeddings = generate_embeddings_batch(combined_texts)\n",
        "\n",
        "df_faqs[\"embedding\"] = embeddings\n",
        "\n",
        "# Verify – show dimension of first embedding\n",
        "dim = len(df_faqs[\"embedding\"].iloc[0])\n",
        "print(f\"\\n✅ Embeddings generated! Dimension: {dim}\")\n",
        "print(f\"   Rows with valid embeddings: {df_faqs['embedding'].notna().sum()}\")"
      ],
      "id": "uO55OB377MQ5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JouMyzgN7MQ5"
      },
      "source": [
        "## Step 5: Store Embeddings in BigQuery\n",
        "\n",
        "We write the enriched DataFrame (original columns + embedding vectors) back to\n",
        "a new BigQuery table. BigQuery natively supports `ARRAY<FLOAT64>` columns,\n",
        "which is exactly what Vertex AI embeddings produce."
      ],
      "id": "JouMyzgN7MQ5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzE_mBmP7MQ5",
        "outputId": "eb8fea14-b117-42f6-a2d5-c31b431d47b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BigQuery schema for embeddings table:\n",
            "  question                       STRING       NULLABLE\n",
            "  answer                         STRING       NULLABLE\n",
            "  combined_text                  STRING       NULLABLE\n",
            "  embedding                      FLOAT64      REPEATED\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 5a. Define explicit BigQuery schema for the embeddings table\n",
        "#\n",
        "# We keep all original columns and add:\n",
        "#   combined_text – the text that was embedded\n",
        "#   embedding     – the vector as ARRAY<FLOAT64>\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "\n",
        "# Build schema dynamically from the DataFrame\n",
        "type_map = {\n",
        "    \"object\":   \"STRING\",\n",
        "    \"int64\":    \"INTEGER\",\n",
        "    \"float64\":  \"FLOAT\",\n",
        "    \"bool\":     \"BOOLEAN\",\n",
        "}\n",
        "\n",
        "schema = []\n",
        "for col in df_faqs.columns:\n",
        "    if col == \"embedding\":\n",
        "        # Embeddings are stored as ARRAY<FLOAT64>\n",
        "        schema.append(\n",
        "            bigquery.SchemaField(col, \"FLOAT64\", mode=\"REPEATED\")\n",
        "        )\n",
        "    else:\n",
        "        bq_type = type_map.get(str(df_faqs[col].dtype), \"STRING\")\n",
        "        schema.append(\n",
        "            bigquery.SchemaField(col, bq_type, mode=\"NULLABLE\")\n",
        "        )\n",
        "\n",
        "print(\"BigQuery schema for embeddings table:\")\n",
        "for field in schema:\n",
        "    print(f\"  {field.name:30s} {field.field_type:12s} {field.mode}\")"
      ],
      "id": "NzE_mBmP7MQ5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK58xCMl7MQ5",
        "outputId": "30ed1896-7cc7-4a8d-dc01-83cf79855a11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Writing 51 rows to:\n",
            "   qwiklabs-gcp-02-689e008843d4.aurora_bay.faqs_with_embeddings\n",
            "\n",
            "✅ Embeddings table ready! Rows: 51\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 5b. Write the enriched DataFrame to BigQuery\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "\n",
        "emb_table_ref = f\"{PROJECT_ID}.{BQ_DATASET}.{BQ_EMB_TABLE}\"\n",
        "\n",
        "job_config_write = bigquery.LoadJobConfig(\n",
        "    schema            = schema,\n",
        "    write_disposition = \"WRITE_TRUNCATE\",  # Overwrite on each run\n",
        ")\n",
        "\n",
        "print(f\"⏳ Writing {len(df_faqs):,} rows to:\\n   {emb_table_ref}\")\n",
        "\n",
        "write_job = bq_client.load_table_from_dataframe(\n",
        "    df_faqs, emb_table_ref, job_config=job_config_write\n",
        ")\n",
        "write_job.result()  # Block until complete\n",
        "\n",
        "written_table = bq_client.get_table(emb_table_ref)\n",
        "print(f\"\\n✅ Embeddings table ready! Rows: {written_table.num_rows:,}\")"
      ],
      "id": "gK58xCMl7MQ5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "_oEqO2Oc7MQ5",
        "outputId": "a0ad597a-d895-4c72-8122-9aa5f23c56ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample rows from the embeddings table:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     question  embedding_dim  first_element\n",
              "0                                    question            768      -0.068221\n",
              "1                When was Aurora Bay founded?            768      -0.079507\n",
              "2       What is the population of Aurora Bay?            768      -0.032302\n",
              "3  Where is the Aurora Bay Town Hall located?            768      -0.068711\n",
              "4     Who is the current mayor of Aurora Bay?            768      -0.075909"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a26349f-1d1b-4a90-a6e3-9e3d4ba54ae0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>embedding_dim</th>\n",
              "      <th>first_element</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>question</td>\n",
              "      <td>768</td>\n",
              "      <td>-0.068221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When was Aurora Bay founded?</td>\n",
              "      <td>768</td>\n",
              "      <td>-0.079507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the population of Aurora Bay?</td>\n",
              "      <td>768</td>\n",
              "      <td>-0.032302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Where is the Aurora Bay Town Hall located?</td>\n",
              "      <td>768</td>\n",
              "      <td>-0.068711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who is the current mayor of Aurora Bay?</td>\n",
              "      <td>768</td>\n",
              "      <td>-0.075909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a26349f-1d1b-4a90-a6e3-9e3d4ba54ae0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a26349f-1d1b-4a90-a6e3-9e3d4ba54ae0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a26349f-1d1b-4a90-a6e3-9e3d4ba54ae0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_de750497-9017-401c-9876-8910bb20d21b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_sanity')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_de750497-9017-401c-9876-8910bb20d21b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_sanity');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_sanity",
              "summary": "{\n  \"name\": \"df_sanity\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"When was Aurora Bay founded?\",\n          \"Who is the current mayor of Aurora Bay?\",\n          \"What is the population of Aurora Bay?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding_dim\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          768\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"first_element\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018859823275073982,\n        \"min\": -0.079507015645504,\n        \"max\": -0.032301537692546844,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.079507015645504\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 5c. Quick sanity check — peek at the stored embeddings\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "sanity_query = f\"\"\"\n",
        "    SELECT\n",
        "        {QUESTION_COL},\n",
        "        ARRAY_LENGTH(embedding)   AS embedding_dim,\n",
        "        embedding[OFFSET(0)]      AS first_element\n",
        "    FROM `{emb_table_ref}`\n",
        "    LIMIT 5\n",
        "\"\"\"\n",
        "\n",
        "df_sanity = bq_client.query(sanity_query).to_dataframe()\n",
        "print(\"Sample rows from the embeddings table:\")\n",
        "df_sanity"
      ],
      "id": "_oEqO2Oc7MQ5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlGwnOxk7MQ5"
      },
      "source": [
        "## Step 6: Build the Vector Search Function\n",
        "\n",
        "We implement cosine similarity search **directly in BigQuery SQL**.\n"
      ],
      "id": "vlGwnOxk7MQ5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "TetsUKAg7MQ5",
        "outputId": "4e10ce06-39da-49e8-bd04-4589f25cfb57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test query: 'What are the visiting hours?'\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  Are there specific quiet hours or noise ordina...   \n",
              "1  What are the operating hours of the Aurora Bay...   \n",
              "2           When are the town council meetings held?   \n",
              "\n",
              "                                              answer  similarity_score  \n",
              "0  Yes. Residential noise ordinances go into effe...            0.5379  \n",
              "1  The library is open Monday through Friday from...            0.5251  \n",
              "2  Town council meetings are held every second Tu...            0.4952  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8698e16-9851-44e5-863f-b87acfaf10de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>similarity_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Are there specific quiet hours or noise ordina...</td>\n",
              "      <td>Yes. Residential noise ordinances go into effe...</td>\n",
              "      <td>0.5379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are the operating hours of the Aurora Bay...</td>\n",
              "      <td>The library is open Monday through Friday from...</td>\n",
              "      <td>0.5251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When are the town council meetings held?</td>\n",
              "      <td>Town council meetings are held every second Tu...</td>\n",
              "      <td>0.4952</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8698e16-9851-44e5-863f-b87acfaf10de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f8698e16-9851-44e5-863f-b87acfaf10de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f8698e16-9851-44e5-863f-b87acfaf10de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_527dcf41-e0b1-42bf-a938-786fc49d501f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_527dcf41-e0b1-42bf-a938-786fc49d501f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Are there specific quiet hours or noise ordinances?\",\n          \"What are the operating hours of the Aurora Bay Public Library?\",\n          \"When are the town council meetings held?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Yes. Residential noise ordinances go into effect from 10 PM to 6 AM on weekdays and from 11 PM to 7 AM on weekends.\",\n          \"The library is open Monday through Friday from 9 AM to 6 PM, and on Saturdays from 10 AM to 4 PM. It\\u2019s closed on Sundays and major holidays.\",\n          \"Town council meetings are held every second Tuesday of the month at 6 PM in the Town Hall conference room. Meetings are open to the public.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similarity_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021913238008108283,\n        \"min\": 0.4952,\n        \"max\": 0.5379,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5379,\n          0.5251,\n          0.4952\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 6a. Vector search helper\n",
        "#\n",
        "# This function:\n",
        "#   1. Embeds the user's question using the same model\n",
        "#   2. Runs a SQL query that computes cosine distance against\n",
        "#      every stored embedding in BigQuery\n",
        "#   3. Returns the top-K closest matches\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "\n",
        "def vector_search(user_question: str, top_k: int = TOP_K) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Find the most semantically similar FAQs to the user's question.\n",
        "\n",
        "    Args:\n",
        "        user_question: Natural language question from the user.\n",
        "        top_k:         Number of top results to return.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with columns [question, answer, similarity_score]\n",
        "        sorted by descending similarity.\n",
        "    \"\"\"\n",
        "    # Step 1 – embed the user question\n",
        "    q_embedding = embedding_model.get_embeddings([user_question])[0].values\n",
        "\n",
        "    # Step 2 – format the vector as a BigQuery ARRAY literal\n",
        "    array_literal = \"[\" + \", \".join(str(v) for v in q_embedding) + \"]\"\n",
        "\n",
        "    # Step 3 – run cosine distance query in BigQuery\n",
        "    # ML.DISTANCE returns cosine *distance* (0 = identical, 2 = opposite)\n",
        "    # so we convert to similarity = 1 - distance for intuitive scoring.\n",
        "    search_sql = f\"\"\"\n",
        "        SELECT\n",
        "            {QUESTION_COL}                            AS question,\n",
        "            {ANSWER_COL}                              AS answer,\n",
        "            ROUND(\n",
        "                1 - ML.DISTANCE(\n",
        "                        embedding,\n",
        "                        {array_literal},\n",
        "                        'COSINE'\n",
        "                    ),\n",
        "                4\n",
        "            )                                         AS similarity_score\n",
        "        FROM `{emb_table_ref}`\n",
        "        ORDER BY similarity_score DESC\n",
        "        LIMIT {top_k}\n",
        "    \"\"\"\n",
        "\n",
        "    df_results = bq_client.query(search_sql).to_dataframe()\n",
        "    return df_results\n",
        "\n",
        "\n",
        "# ── Quick test ──────────────────────────────────────────────\n",
        "test_question = \"What are the visiting hours?\"\n",
        "print(f\"Test query: '{test_question}'\\n\")\n",
        "df_test = vector_search(test_question)\n",
        "df_test"
      ],
      "id": "TetsUKAg7MQ5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyRW1MYG7MQ5"
      },
      "source": [
        "## Step 7: Build the Gemini-Powered Chatbot\n",
        "\n",
        "We combine the vector search results with the user's question into a\n",
        "**retrieval-augmented generation (RAG)** prompt. Gemini uses the retrieved\n",
        "FAQ context to produce a grounded, accurate answer."
      ],
      "id": "tyRW1MYG7MQ5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeMYtfS37MQ6",
        "outputId": "39832f30-1b7b-424d-e2cc-d386839ba69c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gemini model 'gemini-2.0-flash-001' loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 7a. Load the Gemini model\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "\n",
        "gemini = GenerativeModel(\n",
        "    model_name = GEMINI_MODEL,\n",
        "    system_instruction = (\n",
        "        \"You are a helpful and friendly customer-service assistant for Aurora Bay. \"\n",
        "        \"Answer the user's question accurately using ONLY the FAQ context provided. \"\n",
        "        \"If the context does not contain enough information to answer the question, \"\n",
        "        \"say so politely and suggest the user contact Aurora Bay directly. \"\n",
        "        \"Keep your answers concise and easy to understand.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "print(f\"✅ Gemini model '{GEMINI_MODEL}' loaded.\")"
      ],
      "id": "qeMYtfS37MQ6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WMfk4Ld7MQ6",
        "outputId": "e17d652f-a49c-48ef-9e23-d4c4d50b5b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ RAG prompt builder defined.\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 7b. RAG prompt builder\n",
        "#\n",
        "# Formats the retrieved FAQ matches as readable context and\n",
        "# appends the user's question for Gemini to answer.\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "\n",
        "def build_rag_prompt(user_question: str, context_df: pd.DataFrame) -> str:\n",
        "    \"\"\"\n",
        "    Construct a RAG prompt from the user question and retrieved FAQ context.\n",
        "\n",
        "    Args:\n",
        "        user_question: The question posed by the user.\n",
        "        context_df:    DataFrame returned by vector_search().\n",
        "\n",
        "    Returns:\n",
        "        A formatted prompt string ready to send to Gemini.\n",
        "    \"\"\"\n",
        "    context_blocks = []\n",
        "    for i, row in context_df.iterrows():\n",
        "        block = (\n",
        "            f\"--- FAQ {i+1} (similarity: {row['similarity_score']:.4f}) ---\\n\"\n",
        "            f\"Q: {row['question']}\\n\"\n",
        "            f\"A: {row['answer']}\"\n",
        "        )\n",
        "        context_blocks.append(block)\n",
        "\n",
        "    context_str = \"\\n\\n\".join(context_blocks)\n",
        "\n",
        "    prompt = f\"\"\"\\\n",
        "Below are the most relevant Aurora Bay FAQ entries retrieved for this question.\n",
        "Use them to answer the user's question accurately.\n",
        "\n",
        "=== RETRIEVED FAQ CONTEXT ===\n",
        "{context_str}\n",
        "\n",
        "=== USER QUESTION ===\n",
        "{user_question}\n",
        "\n",
        "=== YOUR ANSWER ===\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "print(\"✅ RAG prompt builder defined.\")"
      ],
      "id": "_WMfk4Ld7MQ6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkhKpl0V7MQ6",
        "outputId": "6655b6ba-c23a-46e9-90a1-1c0bb1f81566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Chatbot function defined.\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 7c. Main chatbot function\n",
        "#\n",
        "# Orchestrates: Vector Search → Prompt Building → Gemini → Answer\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "\n",
        "def ask_aurora_bay(user_question: str, top_k: int = TOP_K, verbose: bool = True) -> str:\n",
        "    \"\"\"\n",
        "    Answer a user question about Aurora Bay using RAG.\n",
        "\n",
        "    Pipeline:\n",
        "        1. Embed the question.\n",
        "        2. Vector-search BigQuery for the top-K relevant FAQs.\n",
        "        3. Build a RAG prompt with the retrieved context.\n",
        "        4. Send the prompt to Gemini.\n",
        "        5. Return Gemini's response.\n",
        "\n",
        "    Args:\n",
        "        user_question: The question to answer.\n",
        "        top_k:         Number of FAQ results to retrieve.\n",
        "        verbose:       If True, print retrieved FAQs before the answer.\n",
        "\n",
        "    Returns:\n",
        "        Gemini's answer as a string.\n",
        "    \"\"\"\n",
        "    # ── Step 1 & 2: Vector Search ─────────────────────────────\n",
        "    context_df = vector_search(user_question, top_k=top_k)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"📋 Retrieved FAQ Context:\")\n",
        "        print(\"-\" * 60)\n",
        "        for _, row in context_df.iterrows():\n",
        "            print(f\"  [{row['similarity_score']:.4f}] {row['question']}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    # ── Step 3: Build RAG Prompt ──────────────────────────────\n",
        "    prompt = build_rag_prompt(user_question, context_df)\n",
        "\n",
        "    # ── Step 4: Send to Gemini ────────────────────────────────\n",
        "    response = gemini.generate_content(prompt)\n",
        "\n",
        "    # ── Step 5: Extract and return the answer ─────────────────\n",
        "    answer = response.text.strip()\n",
        "    return answer\n",
        "\n",
        "print(\"✅ Chatbot function defined.\")"
      ],
      "id": "WkhKpl0V7MQ6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVMl4olk7MQ6"
      },
      "source": [
        "## Step 8: Test the Chatbot\n",
        "\n",
        "Run the chatbot against a few sample questions to verify end-to-end functionality."
      ],
      "id": "xVMl4olk7MQ6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyrZychL7MQ6",
        "outputId": "7346b9a5-7343-43d4-b1f2-c3944f6336e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=================================================================\n",
            " 🧑 User: What are the visiting hours at Aurora Bay?\n",
            "=================================================================\n",
            "\n",
            "📋 Retrieved FAQ Context:\n",
            "------------------------------------------------------------\n",
            "  [0.7392] What are the operating hours of the Aurora Bay Public Library?\n",
            "  [0.6962] Is there a local hospital in Aurora Bay?\n",
            "  [0.6669] Does Aurora Bay have public transportation?\n",
            "------------------------------------------------------------\n",
            "\n",
            "🤖 Aurora Bay Assistant:\n",
            "I am sorry, I do not have the information about visiting hours. Please\n",
            "contact Aurora Bay directly for more information.\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# Test 1 – Visiting hours\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "question_1 = \"What are the visiting hours at Aurora Bay?\"\n",
        "\n",
        "print(f\"\\n{'='*65}\")\n",
        "print(f\" 🧑 User: {question_1}\")\n",
        "print(f\"{'='*65}\\n\")\n",
        "\n",
        "answer_1 = ask_aurora_bay(question_1)\n",
        "\n",
        "print(f\"\\n🤖 Aurora Bay Assistant:\")\n",
        "print(textwrap.fill(answer_1, width=70))"
      ],
      "id": "FyrZychL7MQ6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_icwUlU7MQ6",
        "outputId": "80d0ee12-5161-4f89-cfbb-91c81877b1f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=================================================================\n",
            " 🧑 User: Is there parking available?\n",
            "=================================================================\n",
            "\n",
            "📋 Retrieved FAQ Context:\n",
            "------------------------------------------------------------\n",
            "  [0.5288] What are the winter road conditions usually like?\n",
            "  [0.5006] Does Aurora Bay have public transportation?\n",
            "  [0.4874] Are there specific quiet hours or noise ordinances?\n",
            "------------------------------------------------------------\n",
            "\n",
            "🤖 Aurora Bay Assistant:\n",
            "I am sorry, but the FAQ does not contain information about parking.\n",
            "Please contact Aurora Bay directly for more information.\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# Test 2 – Parking / Getting there\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "question_2 = \"Is there parking available?\"\n",
        "\n",
        "print(f\"\\n{'='*65}\")\n",
        "print(f\" 🧑 User: {question_2}\")\n",
        "print(f\"{'='*65}\\n\")\n",
        "\n",
        "answer_2 = ask_aurora_bay(question_2)\n",
        "\n",
        "print(f\"\\n🤖 Aurora Bay Assistant:\")\n",
        "print(textwrap.fill(answer_2, width=70))"
      ],
      "id": "W_icwUlU7MQ6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1sJX_rz7MQ6",
        "outputId": "f0b2b01b-0124-4791-880f-5bbe432f224c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=================================================================\n",
            " 🧑 User: Can I bring my pet dog?\n",
            "=================================================================\n",
            "\n",
            "📋 Retrieved FAQ Context:\n",
            "------------------------------------------------------------\n",
            "  [0.5025] How do I adopt a pet from the local shelter?\n",
            "  [0.4675] Are there specific quiet hours or noise ordinances?\n",
            "  [0.4526] What is the procedure for hosting an event at the waterfront park?\n",
            "------------------------------------------------------------\n",
            "\n",
            "🤖 Aurora Bay Assistant:\n",
            "This question cannot be answered from the given context. Please\n",
            "contact Aurora Bay directly for more information.\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# Test 3 – Out-of-scope question (graceful degradation)\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "question_3 = \"Can I bring my pet dog?\"\n",
        "\n",
        "print(f\"\\n{'='*65}\")\n",
        "print(f\" 🧑 User: {question_3}\")\n",
        "print(f\"{'='*65}\\n\")\n",
        "\n",
        "answer_3 = ask_aurora_bay(question_3)\n",
        "\n",
        "print(f\"\\n🤖 Aurora Bay Assistant:\")\n",
        "print(textwrap.fill(answer_3, width=70))"
      ],
      "id": "_1sJX_rz7MQ6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ8tkDyA7MQ6"
      },
      "source": [
        "## Summary\n",
        "\n",
        "| Step | What was done |\n",
        "|------|---------------|\n",
        "| **1** | Installed and imported all required libraries |\n",
        "| **2** | Configured GCP project, dataset, and model settings |\n",
        "| **3** | Created a BigQuery dataset and loaded the FAQ CSV from GCS |\n",
        "| **4** | Generated semantic embeddings for each Q&A pair using `text-embedding-005` |\n",
        "| **5** | Stored the enriched data (including `ARRAY<FLOAT64>` embeddings) back to BigQuery |\n",
        "| **6** | Built a vector search function using BigQuery's `ML.DISTANCE` (cosine similarity) |\n",
        "| **7** | Built a RAG-based chatbot that passes retrieved context to Gemini |\n",
        "| **8** | Tested the chatbot with sample questions |\n",
        "| **9** | Provided an interactive chat loop for live use |\n",
        "\n",
        "### Key Design Decisions\n",
        "\n",
        "- **Embedding Q+A together** maximises the richness of each vector and improves retrieval recall.\n",
        "- **BigQuery for vector search** keeps everything in one managed service — no separate vector database needed.\n",
        "- **RAG over fine-tuning** is cheaper, faster to update (just reload the CSV), and more transparent.\n",
        "- **Gemini system instruction** anchors the model to FAQ-only responses, preventing hallucination.\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **Scheduled re-embedding**: Use Cloud Scheduler + Cloud Run to refresh embeddings when the FAQ CSV is updated.\n",
        "- **Conversation history**: Pass previous turns to Gemini for multi-turn dialogue.\n",
        "- **Evaluation**: Log user questions and thumbs-up/down feedback for continuous improvement.\n",
        "- **Scaling**: For very large FAQ sets (>1 M rows), consider migrating the vector index to Vertex AI Vector Search (Matching Engine) for sub-millisecond ANN retrieval."
      ],
      "id": "IZ8tkDyA7MQ6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "name": "Challenge 2 .ipynb"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2fa8e44a485433b8a8f78a6ef886140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de77f560c1b64310a371b206c9a6ccf2",
              "IPY_MODEL_f5767e114aa844ecbc51fc1e888599b6",
              "IPY_MODEL_c95c0785aa0b419ca8a02a7aeac5461f"
            ],
            "layout": "IPY_MODEL_49b2146a6c09488e81c196f27070b976"
          }
        },
        "de77f560c1b64310a371b206c9a6ccf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13953e8713e54dcc88997f8cf0e1ec03",
            "placeholder": "​",
            "style": "IPY_MODEL_ed8139d7f6a54d21946b9cfec2ff070d",
            "value": "Embedding batches: 100%"
          }
        },
        "f5767e114aa844ecbc51fc1e888599b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53066e9e118e45f28d168ef91c5ee423",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b92796d8d6140bca3ca0255fc5bc872",
            "value": 1
          }
        },
        "c95c0785aa0b419ca8a02a7aeac5461f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0f48079d7c24f648e4784133dc1a520",
            "placeholder": "​",
            "style": "IPY_MODEL_a52678b552344c42a824a7ed31c37953",
            "value": " 1/1 [00:03&lt;00:00,  3.12s/it]"
          }
        },
        "49b2146a6c09488e81c196f27070b976": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13953e8713e54dcc88997f8cf0e1ec03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed8139d7f6a54d21946b9cfec2ff070d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53066e9e118e45f28d168ef91c5ee423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b92796d8d6140bca3ca0255fc5bc872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0f48079d7c24f648e4784133dc1a520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a52678b552344c42a824a7ed31c37953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}